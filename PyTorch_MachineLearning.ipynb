{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'test', 'labels.txt', 'train']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"./cifar10\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package             Version    \n",
      "------------------- -----------\n",
      "appnope             0.1.0      \n",
      "bleach              2.0.0      \n",
      "Bottleneck          1.2.1      \n",
      "certifi             2018.4.16  \n",
      "chardet             3.0.4      \n",
      "cycler              0.10.0     \n",
      "cymem               2.0.2      \n",
      "cytoolz             0.9.0.1    \n",
      "dataclasses         0.6        \n",
      "decorator           4.0.11     \n",
      "dill                0.2.8.2    \n",
      "entrypoints         0.2.2      \n",
      "fastai              1.0.28     \n",
      "fastprogress        0.1.15     \n",
      "html5lib            0.999999999\n",
      "idna                2.7        \n",
      "ipykernel           4.6.1      \n",
      "ipython             6.0.0      \n",
      "ipython-genutils    0.2.0      \n",
      "ipywidgets          6.0.0      \n",
      "jedi                0.10.2     \n",
      "Jinja2              2.9.6      \n",
      "jsonschema          2.6.0      \n",
      "jupyter             1.0.0      \n",
      "jupyter-client      5.0.1      \n",
      "jupyter-console     5.1.0      \n",
      "jupyter-core        4.3.0      \n",
      "jupyterthemes       0.19.1     \n",
      "kiwisolver          1.0.1      \n",
      "lesscpy             0.13.0     \n",
      "MarkupSafe          1.0        \n",
      "matplotlib          2.2.2      \n",
      "mistune             0.7.4      \n",
      "msgpack             0.5.6      \n",
      "msgpack-numpy       0.4.3.2    \n",
      "murmurhash          1.0.1      \n",
      "nbconvert           5.1.1      \n",
      "nbformat            4.3.0      \n",
      "notebook            5.0.0      \n",
      "numexpr             2.6.8      \n",
      "numpy               1.14.1     \n",
      "pandas              0.23.4     \n",
      "pandocfilters       1.4.1      \n",
      "pexpect             4.2.1      \n",
      "pickleshare         0.7.4      \n",
      "Pillow              5.0.0      \n",
      "pip                 10.0.1     \n",
      "plac                0.9.6      \n",
      "ply                 3.11       \n",
      "preshed             2.0.1      \n",
      "prompt-toolkit      1.0.14     \n",
      "protobuf            3.1.0      \n",
      "ptyprocess          0.5.1      \n",
      "Pygments            2.2.0      \n",
      "pyparsing           2.2.0      \n",
      "python-dateutil     2.6.0      \n",
      "pytz                2018.4     \n",
      "PyYAML              3.12       \n",
      "pyzmq               16.0.2     \n",
      "qtconsole           4.3.0      \n",
      "regex               2018.11.22 \n",
      "requests            2.19.1     \n",
      "scipy               1.1.0      \n",
      "setuptools          38.5.2     \n",
      "simplegeneric       0.8.1      \n",
      "six                 1.11.0     \n",
      "spacy               2.0.16     \n",
      "tensorflow          0.12.0     \n",
      "terminado           0.6        \n",
      "testpath            0.3        \n",
      "thinc               6.12.0     \n",
      "toolz               0.9.0      \n",
      "torch               0.3.0.post4\n",
      "torchvision         0.2.0      \n",
      "torchvision-nightly 0.2.1      \n",
      "tornado             4.5.1      \n",
      "tqdm                4.24.0     \n",
      "traitlets           4.3.2      \n",
      "typing              3.6.6      \n",
      "ujson               1.35       \n",
      "urllib3             1.22       \n",
      "wcwidth             0.1.7      \n",
      "webencodings        0.5.1      \n",
      "wheel               0.30.0     \n",
      "widgetsnbextension  2.0.0      \n",
      "wrapt               1.10.11    \n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0248d665b8152f0f4ab91b5701fef187fc415d7"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "## *Speed tricks:*\n",
    "- Use Pillow-SIMD instead of PIL. OpenCV is slow.\n",
    "- Use half / mixed precision and double your batch size to achieve more than 30-40% speedup in training and also to lower model size for on-device inference\n",
    "- [CV] Go for distributed IF AND ONLY IF you have a super large dataset - Large by size and number of images. Be rest assured the same hyperparameters might not be optimal for both the training modes.\n",
    "- http://www.fast.ai/2018/07/02/adam-weight-decay/\n",
    "\n",
    "## Datasets for experiments and exercises:\n",
    "Datasets:\n",
    "    - Cifar: http://files.fast.ai/data/\n",
    "    - Indian Snacks: https://github.com/NavinManaswi/IndianSnacks\n",
    "- To create your own dataset - https://github.com/hardikvasa/google-images-download\n",
    "\n",
    "# References\n",
    "## 7. PyTorch Tips:\n",
    "- Always remember to do `.eval()` before inference.\n",
    "- Always remember to zero your gradients using `.zero_grad()` in your training loop. Gradients accumulate (sum) by default.\n",
    "- For complete reproducitibility on GPU, disable cuDNN `torch.backends.cudnn.enabled = False`\n",
    "- `num_workers` and `pin_memory` enable fast data-loading from disk and transfer between RAM & GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "0337c970b92cc10f6dc82a4e9717469bc4ee11ed",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Extract cifar zip file\n",
    "! tar -xf ./cifar10.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "4052e216a3c94143c87582fd40409b3d5aa4e4dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0.3.0.post4', None, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, torch.version.cuda, torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "829708dba49dd17da643de77049a272772fb69ab"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "d5bb416d725c66efd354a9fef9d7037e8d7004f3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        return self.fc1(features)\n",
    "    \n",
    "m = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "07ffba467ec802abed0f87c5fa89a4cd27fb7a12",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = np.random.rand(10, 2)\n",
    "y = data[:,0] + 1.65*data[:,1]\n",
    "\n",
    "data = Variable(torch.FloatTensor(data), requires_grad=True)\n",
    "y = Variable(torch.FloatTensor(y)).view(-1,1)#, volatile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "665f69c1116e5740c2aa360ddd5310f3afe24ab6",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1.00000e-09 *\n",
      "  6.5013\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "25 \n",
      "1.00000e-09 *\n",
      "  4.2585\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "50 \n",
      "1.00000e-09 *\n",
      "  2.7970\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "75 \n",
      "1.00000e-09 *\n",
      "  1.8319\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "100 \n",
      "1.00000e-09 *\n",
      "  1.2044\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "125 \n",
      "1.00000e-10 *\n",
      "  7.9219\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "150 \n",
      "1.00000e-10 *\n",
      "  5.2059\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "175 \n",
      "1.00000e-10 *\n",
      "  3.4120\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "200 \n",
      "1.00000e-10 *\n",
      "  2.2424\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "225 \n",
      "1.00000e-10 *\n",
      "  1.4785\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "250 \n",
      "1.00000e-11 *\n",
      "  9.7508\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "275 \n",
      "1.00000e-11 *\n",
      "  6.4065\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "300 \n",
      "1.00000e-11 *\n",
      "  4.3797\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "325 \n",
      "1.00000e-11 *\n",
      "  2.9293\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "350 \n",
      "1.00000e-11 *\n",
      "  1.9039\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "375 \n",
      "1.00000e-11 *\n",
      "  1.1566\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "400 \n",
      "1.00000e-12 *\n",
      "  7.8129\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "425 \n",
      "1.00000e-12 *\n",
      "  5.5221\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "450 \n",
      "1.00000e-12 *\n",
      "  3.8604\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "475 \n",
      "1.00000e-12 *\n",
      "  2.8543\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "\n",
    "crit = torch.nn.MSELoss()\n",
    "opt = optim.SGD(m.parameters(), lr=0.1)\n",
    "\n",
    "for t, i in enumerate(range(epochs)):\n",
    "    y_pred = m(data)\n",
    "    loss = crit(y_pred, y)\n",
    "    if t % 25 == 0:\n",
    "        print(t, loss.data)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "a1a1c390930cd21dba41b4c01248721235efd590",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       "  1.0000  1.6500\n",
       " [torch.FloatTensor of size 1x2], Parameter containing:\n",
       " 1.00000e-06 *\n",
       "   3.8803\n",
       " [torch.FloatTensor of size 1]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "48a89e476b28a5798a01f3a73e637e19717134aa"
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "c8bb03b5e961f8658310dea0132724b5214e453d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  2\n",
       " 3  4\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1, 2], [3,4]])\n",
    "test = Variable(t)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "ce9ffb14013d4fdc849921cd278d68d2f7eb586b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "  (fc1): Linear(in_features=2, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch the mode of the model into evaluation. As BatchNorm and Dropout layers behave differently during training and inference, this is critical!\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "0dba2692669bdcfa607148e5eb0e58e57ce6c40e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4.3000\n",
       " 9.6000\n",
       "[torch.FloatTensor of size 2x1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2b72d4b49c65d80185d426ab2907727d35cf1c9"
   },
   "source": [
    "### Save the weights\n",
    "This PyTorch model can be reused for scoring predictions during test time. For this, the weights of the model can be saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "9302394bd804375274a967608ff6755849af800a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight', \n",
       "               1.0000  1.6500\n",
       "              [torch.FloatTensor of size 1x2]), ('fc1.bias', \n",
       "              1.00000e-06 *\n",
       "                3.8803\n",
       "              [torch.FloatTensor of size 1])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "68d7c671c6cc78aac516bebf9f848a3fef6d1098",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), 'linear.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "0f06e6f53562130f0ab443ed33804b3e9bc41356",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "9c743b653a6d60836bd4abc9546c8b23e70f12d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight', \n",
       "               0.1714  0.5793\n",
       "              [torch.FloatTensor of size 1x2]), ('fc1.bias', \n",
       "              -0.2821\n",
       "              [torch.FloatTensor of size 1])])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearRegression()\n",
    "m.state_dict() # Random weights are assigned on initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "55ff63aed1fb1d8bcb2723f3616a134aeb085ade",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.load_state_dict(torch.load('linear.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "a1334aa5fbe8b5dbc1476bee294642c01e6c9637",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight', \n",
       "               1.0000  1.6500\n",
       "              [torch.FloatTensor of size 1x2]), ('fc1.bias', \n",
       "              1.00000e-06 *\n",
       "                3.8803\n",
       "              [torch.FloatTensor of size 1])])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "422542d7f60e26fb784bdaa7c8811bcf9c20e9e7"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "4047983e6cbe4598903fab2fae604a219b12f153",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, features):\n",
    "        return torch.sigmoid(self.fc1(features))\n",
    "    \n",
    "m = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "07ffba467ec802abed0f87c5fa89a4cd27fb7a12",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = np.random.rand(10, 2)\n",
    "y = data[:,0] + 1.65*data[:,1]\n",
    "y = 1. / (1 + np.exp(-y))\n",
    "y = (y - min(y)) / (max(y) - min(y))\n",
    "y = np.digitize(y, [0.5])\n",
    "\n",
    "data = Variable(torch.FloatTensor(data), requires_grad=True)\n",
    "y = Variable(torch.FloatTensor(y))#, volatile=True)\n",
    "y = y.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "7afa6cbac4e674e34122a969d2d0f47f3c3d9981",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " 1.0035\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "100 \n",
      " 0.3540\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "200 \n",
      " 0.2668\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "300 \n",
      " 0.2213\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "400 \n",
      " 0.1935\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "500 \n",
      " 0.1745\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "600 \n",
      " 0.1606\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "700 \n",
      " 0.1499\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "800 \n",
      " 0.1414\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "900 \n",
      " 0.1344\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1000 \n",
      " 0.1284\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1100 \n",
      " 0.1233\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1200 \n",
      " 0.1189\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1300 \n",
      " 0.1149\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1400 \n",
      " 0.1114\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1500 \n",
      " 0.1082\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1600 \n",
      " 0.1054\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1700 \n",
      " 0.1027\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1800 \n",
      " 0.1003\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1900 \n",
      "1.00000e-02 *\n",
      "  9.8001\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2000 \n",
      "1.00000e-02 *\n",
      "  9.5891\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2100 \n",
      "1.00000e-02 *\n",
      "  9.3918\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2200 \n",
      "1.00000e-02 *\n",
      "  9.2065\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2300 \n",
      "1.00000e-02 *\n",
      "  9.0319\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2400 \n",
      "1.00000e-02 *\n",
      "  8.8668\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2500 \n",
      "1.00000e-02 *\n",
      "  8.7104\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2600 \n",
      "1.00000e-02 *\n",
      "  8.5618\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2700 \n",
      "1.00000e-02 *\n",
      "  8.4203\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2800 \n",
      "1.00000e-02 *\n",
      "  8.2852\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2900 \n",
      "1.00000e-02 *\n",
      "  8.1560\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3000 \n",
      "1.00000e-02 *\n",
      "  8.0322\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3100 \n",
      "1.00000e-02 *\n",
      "  7.9135\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3200 \n",
      "1.00000e-02 *\n",
      "  7.7993\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3300 \n",
      "1.00000e-02 *\n",
      "  7.6895\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3400 \n",
      "1.00000e-02 *\n",
      "  7.5837\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3500 \n",
      "1.00000e-02 *\n",
      "  7.4815\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3600 \n",
      "1.00000e-02 *\n",
      "  7.3829\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3700 \n",
      "1.00000e-02 *\n",
      "  7.2875\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3800 \n",
      "1.00000e-02 *\n",
      "  7.1952\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "3900 \n",
      "1.00000e-02 *\n",
      "  7.1058\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4000 \n",
      "1.00000e-02 *\n",
      "  7.0191\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4100 \n",
      "1.00000e-02 *\n",
      "  6.9349\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4200 \n",
      "1.00000e-02 *\n",
      "  6.8532\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4300 \n",
      "1.00000e-02 *\n",
      "  6.7738\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4400 \n",
      "1.00000e-02 *\n",
      "  6.6965\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4500 \n",
      "1.00000e-02 *\n",
      "  6.6213\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4600 \n",
      "1.00000e-02 *\n",
      "  6.5481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4700 \n",
      "1.00000e-02 *\n",
      "  6.4768\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4800 \n",
      "1.00000e-02 *\n",
      "  6.4072\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "4900 \n",
      "1.00000e-02 *\n",
      "  6.3393\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "crit = torch.nn.BCELoss()\n",
    "opt = optim.SGD(m.parameters(), lr=0.5)\n",
    "\n",
    "for t, i in enumerate(range(epochs)):\n",
    "    y_pred = m(data)\n",
    "    loss = crit(y_pred, y)\n",
    "    if t % 100 == 0:\n",
    "        print(t, loss.data)\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "6bbe2aa84de291c114bad5cd425f7ba12c38bb93",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       "  10.9111  17.4337\n",
       " [torch.FloatTensor of size 1x2], Parameter containing:\n",
       " -10.7229\n",
       " [torch.FloatTensor of size 1]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(m.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6fc3c8cc41b8ca3f94c370c92ed47bf0d3d8329"
   },
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "8c6e046b5755b11aed656c1186901e9c7f0cae0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.1400  0.1400\n",
       " 0.2400  0.6700\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[0.14, 0.14], [0.24,0.67]])\n",
    "test = Variable(t)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "1cc4e7985a63dd23668a1a1e2b7bdfcc2a29ea5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (fc1): Linear(in_features=2, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "_uuid": "aa343428c04fb67f58a0cb646e94214c97fbbe40"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0012\n",
       " 0.9728\n",
       "[torch.FloatTensor of size 2x1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5a03b0b99c71002d003b7eb9ffebe51fd76342d",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86730197596de009e2ca6fa28d5039d8f8c1ed54",
    "collapsed": true
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1467618924425d1609e1b18357562a470c2a1d0",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls cifar10/\n",
    "# ! rm cifar10/labels.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9a0c131d806bbb94a58dd5587121984ac475a177",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls cifar10/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b34285d9e5d681540c8d775fae97482a5ec20765",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cifar10/labels.txt\", \"r\") as f:\n",
    "    labels = f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6623d36cd5baab5d5bd02a6c8db358cada176016",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c395fbec5818a2e89379ddf4155f29f819ea4f38",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "train_dataset = datasets.ImageFolder('cifar10/train', transform=data_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=2, pin_memory=True, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder('cifar10/test', transform=data_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=2, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "27a30846c83e0ff1a5939c2d4eb2fd002a6ecd3c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "195cfb48860edcd5735d6cc9f4802efd95221483",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, classes = dataiter.next()\n",
    "images = images.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d3628a8c9d30022d24591326baeb25f6807db104",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f23012679e2e39954131427834d2eab224827bd5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
    "    ax.set_title(labels[classes[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6cfb9d17faa0d03dd455eb5d30903acd94a7f986",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A rudimentary network\n",
    "class simplenet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(simplenet, self).__init__()\n",
    "        #32*32*3\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
    "        #16*16*64\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dd01ed4a2f5173537f948a3f4a84146ee8f2ec6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = simplenet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "091f35791a45f11e98ec3243b710deac0c99506c",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(m.parameters(), lr=0.1)\n",
    "\n",
    "for t, i in enumerate(range(epochs)):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    match = 0\n",
    "    m.train()\n",
    "    for data, y in train_loader:\n",
    "        data, y = data.cuda(), y.cuda()\n",
    "        opt.zero_grad()\n",
    "        y_pred = m(data)\n",
    "        loss = crit(y_pred, y)\n",
    "        \n",
    "        _, pred = torch.max(y_pred, 1)\n",
    "        match += np.sum(pred.eq(y.data.view_as(pred)).cpu().numpy())\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    train_accuracy = match/len(train_loader.dataset)\n",
    "    \n",
    "    print(t, train_loss, train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "572dd384869207121aac082d75bd7db1f3255a3a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(m.state_dict(), 'model_cifar.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91f3907308fad8892024d4e6e8274a70b9dc1d69",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e01ee6e2a44a072488227fb408e75bfc16bb4ba7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = simplenet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43d6bf83c6553ff634fa396f0408617ce86a0776",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.load_state_dict(torch.load('model_cifar.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fbf7b80cfb07c6179d2a86188c1856c57a2e2bdc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "79fca5740a060c859f77d27de00da6cac6171e4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_loss = 0.0\n",
    "match = 0\n",
    "m.eval()\n",
    "for data, y in test_loader:\n",
    "    data, y = data.cuda(), y.cuda()\n",
    "    y_pred = m(data)\n",
    "    \n",
    "#     loss = crit(y_pred, y)\n",
    "#     test_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    _, pred = torch.max(y_pred, 1)\n",
    "    match += np.sum(pred.eq(y.data.view_as(pred)).cpu().numpy())\n",
    "\n",
    "# test_loss = test_loss/len(test_loader.dataset)\n",
    "test_accuracy = match/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de55b783acf818f31673aa2c7103b07025f22727",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7eb3377e70caf8f6d769ce8eccfebec0d5d2d6bb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add validation - yes p0\n",
    "# comment the code - p3\n",
    "# transfer learning - Resnet50 p1\n",
    "# List all the pre trained models p2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8647473147fe530cc8b1a324dbe4ed02551f635b"
   },
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "f9263d726f21785d648a70623dab3aa7968ff7a8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.4914, 0.48216, 0.44653],\n",
    "                                                            std=[0.24703, 0.24349, 0.26159])])\n",
    "\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.4914, 0.48216, 0.44653],\n",
    "                                                           std=[0.24703, 0.24349, 0.26159])])\n",
    "\n",
    "train_dataset = datasets.ImageFolder('cifar10/train', transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, num_workers=2, pin_memory=True, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.ImageFolder('cifar10/test', transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=2, pin_memory=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "_uuid": "7cc92711d04f49e4ca7f59a0b1b410e8eacf1061",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.init' has no attribute 'kaiming_normal_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-25c162d114aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mresnet18\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mpretrained\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mpre\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrained\u001b[0m \u001b[0mon\u001b[0m \u001b[0mImageNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBasicBlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_urls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resnet18'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, layers, num_classes)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.init' has no attribute 'kaiming_normal_'"
     ]
    }
   ],
   "source": [
    "m = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "_uuid": "acaa008d0bad621f25e4367b406d7b11ac461eeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (fc1): Linear(in_features=2, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "129e06539f828def65f838299ae95943e9e29ee3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3029476912b164a7e1d755967054d51ad064394a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in m.parameters():\n",
    "    param.requires_grad = False\n",
    "from collections import OrderedDict\n",
    "fc = nn.Sequential(OrderedDict([\n",
    "                          ('output', nn.Linear(512, 10))\n",
    "                          ]))\n",
    "m.fc = fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b1b1130704c57ec52b21920368a6ca0be12ae34",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fbffd3402bf40f4c935b9e8865b213f4ffbd8a1b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for p in m.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96562db363634da6588ca303ceec3ddc4a6ebfdd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(m.fc.parameters(), lr=0.1)\n",
    "\n",
    "for t, i in enumerate(range(epochs)):\n",
    "\n",
    "    train_loss = 0.0\n",
    "    match = 0\n",
    "    for data, y in train_loader:\n",
    "        data, y = data.cuda(), y.cuda()\n",
    "        opt.zero_grad()\n",
    "        y_pred = m(data)\n",
    "        loss = crit(y_pred, y)\n",
    "        \n",
    "        _, pred = torch.max(y_pred, 1)\n",
    "        match += np.sum(pred.eq(y.data.view_as(pred)).cpu().numpy())\n",
    "        \n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "    train_loss = train_loss/len(train_loader.dataset)\n",
    "    train_accuracy = match/len(train_loader.dataset)\n",
    "    \n",
    "    print(t, train_loss, train_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "248f467e676463c2cf06123cec09d3c64f789240"
   },
   "source": [
    "https://pytorch.org/docs/stable/torchvision/models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b34db0cfde24be2b2deae6bdecbf48fae161546",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
